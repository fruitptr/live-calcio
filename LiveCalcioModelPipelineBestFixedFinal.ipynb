{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2xNQQuVe6i2",
        "outputId": "568bc250-d331-4ad6-a2af-de3c174542d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.8/91.8 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.0/755.0 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.0/108.0 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.3/99.3 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.2/127.2 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install fastapi uvicorn ultralytics tensorflow torch requests pyngrok nest-asyncio pypi-json pydantic moviepy pillow  -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UVyIi3q4fLQg",
        "outputId": "aa8f6746-e846-45f5-9062-cc7c5638e809"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BqzUpps4aU0",
        "outputId": "ea32159f-f122-4797-ae98-b192503fa7c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ffmpeg-python\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from ffmpeg-python) (0.18.3)\n",
            "Installing collected packages: ffmpeg-python\n",
            "Successfully installed ffmpeg-python-0.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip install ffmpeg-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rBrpp3m6w2HW"
      },
      "outputs": [],
      "source": [
        "import ffmpeg\n",
        "\n",
        "def trim_video(starting_frame, ending_frame):\n",
        "  print(\"In trim video\")\n",
        "  print(\"Start frame: \", starting_frame)\n",
        "  print(\"End frame: \", ending_frame)\n",
        "  if os.path.exists('/content/video.mp4'):\n",
        "        os.remove('/content/video.mp4')\n",
        "        print(\"Deleted existing 'video.mp4'\")\n",
        "  input_file = ffmpeg.input('/content/origVideo.mp4')\n",
        "  output_file = ffmpeg.output(input_file.trim(start_frame=starting_frame, end_frame=ending_frame).setpts('PTS-STARTPTS'), 'video.mp4')\n",
        "  ffmpeg.run(output_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eDxzFpQHf-9k"
      },
      "outputs": [],
      "source": [
        "from IPython import display as dp\n",
        "from ultralytics import YOLO\n",
        "from IPython.display import display, Image\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.notebook import tqdm\n",
        "from glob import glob\n",
        "from random import sample\n",
        "from PIL import Image, ImageFont, ImageDraw, ImageEnhance, ImageFilter\n",
        "from pathlib import Path\n",
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "import cv2\n",
        "import random\n",
        "import torch\n",
        "from tensorflow.keras.preprocessing.image import array_to_img\n",
        "import requests\n",
        "from pydantic import BaseModel\n",
        "import math\n",
        "\n",
        "class model_input(BaseModel):\n",
        "  video : str\n",
        "  x : int\n",
        "  y : int\n",
        "  timestamp: int\n",
        "\n",
        "def get_last_frame(video_url):\n",
        "  print(\"In get_last_frame\")\n",
        "  cap = cv2.VideoCapture(video_url)\n",
        "  total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "  cap.set(cv2.CAP_PROP_POS_FRAMES, total_frames - 1)\n",
        "  ret, frame = cap.read()\n",
        "  cap.release()\n",
        "\n",
        "  cv2.imwrite('/content/last_frame.png', frame)\n",
        "\n",
        "  return frame\n",
        "\n",
        "def load_person_dect_model(video_url):\n",
        "  print(\"In load_person_dect_model\")\n",
        "  model = YOLO('yolov8m.pt')\n",
        "  results = model.track(source=video_url, conf=0.25, save=True, tracker='bytetrack.yaml', classes=0)\n",
        "  return results\n",
        "\n",
        "def get_tapped_box(results, tap_coord):\n",
        "    print(\"In get_tapped_box\")\n",
        "    last_frame_index = len(results) - 1\n",
        "    last_frame_boxes = results[last_frame_index].boxes.xyxy.tolist()\n",
        "    required_track_id = None\n",
        "    min_distance = float('inf')\n",
        "\n",
        "    for index, box in enumerate(last_frame_boxes):\n",
        "        x_min, y_min, x_max, y_max = box\n",
        "        box_center = ((x_min + x_max) / 2, (y_min + y_max) / 2)\n",
        "        tap_distance = math.sqrt((tap_coord[0] - box_center[0]) ** 2 + (tap_coord[1] - box_center[1]) ** 2)\n",
        "\n",
        "        if tap_distance < min_distance:\n",
        "            min_distance = tap_distance\n",
        "            required_track_id = results[last_frame_index].boxes[index].id.tolist()[0]\n",
        "            print(\"Tracking ID: \", required_track_id)\n",
        "\n",
        "    return required_track_id if required_track_id is not None else None\n",
        "\n",
        "def get_jersey_color(last_frame_image, tap_coord):\n",
        "    print(\"In get_jersey_color\")\n",
        "    cropped_img = None\n",
        "    player_found = False\n",
        "\n",
        "    model = YOLO('yolov8m.pt')\n",
        "    frame_result = model.predict(source='/content/last_frame.png', conf=0.25, save=True, classes=0)\n",
        "    last_frame_boxes = frame_result[0].boxes.xyxy.tolist()\n",
        "    print(\"LAST FRAME BOXES: \")\n",
        "    print(last_frame_boxes)\n",
        "\n",
        "    min_distance = float('inf')\n",
        "    closest_box = None\n",
        "\n",
        "    print(\"Tap Coord:\", tap_coord)\n",
        "\n",
        "    for index, box in enumerate(last_frame_boxes):\n",
        "        x_min, y_min, x_max, y_max = map(int, box)\n",
        "        box_center = ((x_min + x_max) / 2, (y_min + y_max) / 2)\n",
        "        tap_distance = math.sqrt((tap_coord[0] - box_center[0]) ** 2 + (tap_coord[1] - box_center[1]) ** 2)\n",
        "\n",
        "        if tap_distance < min_distance:\n",
        "            min_distance = tap_distance\n",
        "            closest_box = box\n",
        "\n",
        "    print(\"Min distance: \", min_distance)\n",
        "    if min_distance > 300:\n",
        "      return False\n",
        "\n",
        "    if closest_box is not None:\n",
        "        x_min, y_min, x_max, y_max = map(int, closest_box)\n",
        "        y_max = (y_min + y_max) // 2\n",
        "        cropped_img = last_frame_image[y_min:y_max, x_min:x_max].copy()\n",
        "        player_found = True\n",
        "        print(\"Cropping frame\")\n",
        "        cv2.imwrite('/content/cropped_frame.png', cropped_img)\n",
        "\n",
        "    if not player_found:\n",
        "        return False\n",
        "\n",
        "    hsv_cropped_img = cv2.cvtColor(cropped_img, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "    lower_red = np.array([0,50,50])\n",
        "    upper_red = np.array([10,255,255])\n",
        "    mask0 = cv2.inRange(hsv_cropped_img, lower_red, upper_red)\n",
        "\n",
        "    lower_red = np.array([170,50,50])\n",
        "    upper_red = np.array([180,255,255])\n",
        "    mask1 = cv2.inRange(hsv_cropped_img, lower_red, upper_red)\n",
        "\n",
        "    mask_red = mask0+mask1\n",
        "\n",
        "    cv2.imwrite('/content/mask_red.png', mask_red)\n",
        "\n",
        "    cropped_img_gray = cv2.cvtColor(cropped_img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    total_pixels = cv2.countNonZero(cropped_img_gray)\n",
        "    red_pixels = cv2.countNonZero(mask_red)\n",
        "    red_percentage = (red_pixels / total_pixels) * 100\n",
        "\n",
        "    red_threshold = 15\n",
        "    print(\"Red percentage: \", red_percentage)\n",
        "    if red_percentage >= red_threshold:\n",
        "        return True\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "def load_jersey_dect_model():\n",
        "  print(\"In load_jersey_dect_model\")\n",
        "  jersey_model = torch.hub.load('ultralytics/yolov5', 'custom', path='/content/drive/MyDrive/yolov5ID_640_100epoch.pt')\n",
        "  jersey_model.load_state_dict(torch.load('/content/drive/MyDrive/yolov5ID_640_100epoch.pt')['model'].state_dict(), strict=False)\n",
        "  return jersey_model\n",
        "\n",
        "def clear_output_folder():\n",
        "  print(\"In clear_output_folder\")\n",
        "  output_folder = '/content/cropped_images/'\n",
        "\n",
        "  if os.path.exists(output_folder):\n",
        "      shutil.rmtree(output_folder)\n",
        "  os.makedirs(output_folder)\n",
        "\n",
        "def pre_process_images(results, required_track_id):\n",
        "  print(\"In pre_process_images\")\n",
        "  image_paths = []\n",
        "  output_folder = '/content/cropped_images/'\n",
        "\n",
        "  for result_index, result in enumerate(results):\n",
        "      for box_index, box in enumerate(result.boxes):\n",
        "          if box.id is not None:\n",
        "            current_track_id = box.id.tolist()[0]\n",
        "\n",
        "          if current_track_id == required_track_id:\n",
        "              x_min, y_min, x_max, y_max = box.xyxy.tolist()[0]\n",
        "              orig_img_bgr = result.orig_img\n",
        "\n",
        "              orig_img_rgb = cv2.cvtColor(orig_img_bgr, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "              orig_img = Image.fromarray(orig_img_rgb)\n",
        "\n",
        "              cropped_img = orig_img.crop((x_min, y_min, x_max, y_max))\n",
        "\n",
        "              enlarged_size = (cropped_img.width * 2, cropped_img.height * 2)\n",
        "              cropped_img = cropped_img.resize(enlarged_size, Image.BICUBIC)\n",
        "\n",
        "              cropped_img_sharpened = cropped_img.filter(ImageFilter.SHARPEN)\n",
        "              cropped_img_sharpened = cropped_img_sharpened.filter(ImageFilter.SHARPEN)\n",
        "\n",
        "              image_filename = f'cropped_image_{result_index}_box_{box_index}_sharpened.png'\n",
        "              image_path = os.path.join(output_folder, image_filename)\n",
        "              cropped_img_sharpened.save(image_path)\n",
        "\n",
        "              image_paths.append(image_path)\n",
        "\n",
        "  return image_paths\n",
        "\n",
        "def predict_number(img, model):\n",
        "  print(\"In predict_number\")\n",
        "  im = array_to_img(img)\n",
        "  output = model(im)\n",
        "  results = output.pandas().xyxy[0].to_dict(orient=\"records\")\n",
        "  for result in results:\n",
        "      cs = result['class']\n",
        "      return cs\n",
        "\n",
        "def get_jersey_number(image_paths, model):\n",
        "  print(\"In get_jersey_number\")\n",
        "  num_dict = {}\n",
        "\n",
        "  for path in image_paths:\n",
        "    img = cv2.imread(path)\n",
        "    num = predict_number(img, model)\n",
        "    if num is not None:\n",
        "      if num not in num_dict:\n",
        "        num_dict[num] = 1\n",
        "      else:\n",
        "        num_dict[num] += 1\n",
        "\n",
        "  if bool(num_dict) == False:\n",
        "    return None\n",
        "\n",
        "  print(num_dict)\n",
        "\n",
        "  return max(num_dict, key=num_dict.get)\n",
        "\n",
        "\n",
        "def download_video(video_url, save_path, starting_frame, ending_frame):\n",
        "    print(\"In download_video\")\n",
        "    response = requests.get(video_url, stream=True)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        with open(save_path, 'wb') as file:\n",
        "            for chunk in response.iter_content(chunk_size=1024*1024):\n",
        "                file.write(chunk)\n",
        "        print(\"Video downloaded\")\n",
        "        trim_video(starting_frame, ending_frame)\n",
        "        return True\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "\n",
        "\n",
        "def predict_jersey(video_url, tap_coords, starting_frame, ending_frame):\n",
        "  dp.clear_output()\n",
        "\n",
        "  video_filename = 'video.mp4'\n",
        "  download_path = os.path.join('.', 'origVideo.mp4')\n",
        "  if not download_video(video_url, download_path, starting_frame, ending_frame):\n",
        "      return \"Failed to download the video\"\n",
        "\n",
        "  last_frame_image = get_last_frame(video_filename)\n",
        "  if get_jersey_color(last_frame_image, tap_coords):\n",
        "    results = load_person_dect_model(video_filename)\n",
        "    bbox_id = get_tapped_box(results, tap_coords)\n",
        "    if bbox_id == None:\n",
        "      return \"Not a player\"\n",
        "    else:\n",
        "      model = load_jersey_dect_model()\n",
        "      clear_output_folder()\n",
        "      image_paths = pre_process_images(results, bbox_id)\n",
        "      jersey_number = get_jersey_number(image_paths, model)\n",
        "      if jersey_number == None:\n",
        "        return \"Cannot identify\"\n",
        "      else:\n",
        "        return jersey_number\n",
        "  else:\n",
        "    return \"Not a player (Jersey color is not red)\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xd89L90cfUBB"
      },
      "outputs": [],
      "source": [
        "from fastapi import FastAPI\n",
        "from fastapi.middleware.cors import CORSMiddleware\n",
        "import uvicorn\n",
        "from pyngrok import ngrok, conf\n",
        "import nest_asyncio\n",
        "import json\n",
        "import math\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "origins = [\"*\"]\n",
        "app.add_middleware(\n",
        "    CORSMiddleware,\n",
        "    allow_origins=origins,\n",
        "    allow_credentials=True,\n",
        "    allow_methods=[\"*\"],\n",
        "    allow_headers=[\"*\"],\n",
        ")\n",
        "\n",
        "@app.post(\"/predict/\")\n",
        "async def predict_jersey_number(input_parameters : model_input):\n",
        "    input_data = input_parameters.json()\n",
        "    input_dictionary = json.loads(input_data)\n",
        "    tap_coords = (input_dictionary['x'], input_dictionary['y'])\n",
        "    timestamp = input_dictionary['timestamp']\n",
        "    ending_frame = round((timestamp / 1000) * 30)\n",
        "    print(\"Ending frame: \", ending_frame)\n",
        "    starting_frame = ending_frame - 50\n",
        "    if starting_frame < 0:\n",
        "      starting_frame = 0\n",
        "    print(\"Starting frame: \", starting_frame)\n",
        "    number = predict_jersey(input_dictionary['video'], tap_coords, starting_frame, ending_frame)\n",
        "    return {\"jersey_number\": number}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bMENnWCcfeTG",
        "outputId": "c2e94566-0a3e-41e2-e2f4-be5d052cd8bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In download_video\n",
            "Video downloaded\n",
            "In trim video\n",
            "Start frame:  124\n",
            "End frame:  174\n",
            "Deleted existing 'video.mp4'\n",
            "In get_last_frame\n",
            "In get_jersey_color\n",
            "\n",
            "image 1/1 /content/last_frame.png: 384x640 16 persons, 1442.7ms\n",
            "Speed: 3.9ms preprocess, 1442.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict10\u001b[0m\n",
            "LAST FRAME BOXES: \n",
            "[[508.8204345703125, 805.0352783203125, 560.9170532226562, 958.8043212890625], [1615.784912109375, 769.68603515625, 1715.174560546875, 916.2235107421875], [1304.4517822265625, 625.646728515625, 1357.087646484375, 738.466796875], [1600.361572265625, 411.3262023925781, 1636.077392578125, 494.4817199707031], [1763.80517578125, 493.08343505859375, 1837.985595703125, 589.64892578125], [1025.79541015625, 539.2002563476562, 1064.63671875, 634.5330200195312], [720.7963256835938, 509.5022277832031, 761.9129638671875, 608.99072265625], [569.3326416015625, 395.3762512207031, 606.2785034179688, 473.3229675292969], [211.56207275390625, 609.0228881835938, 291.40313720703125, 736.7587280273438], [1010.6874389648438, 394.8787536621094, 1063.427978515625, 468.6252136230469], [1640.789794921875, 369.2643127441406, 1667.640380859375, 443.9015808105469], [468.0721435546875, 351.8162841796875, 503.750244140625, 417.8302001953125], [763.2744750976562, 372.6089172363281, 815.46044921875, 450.1604919433594], [968.4166259765625, 306.1875305175781, 996.66943359375, 377.6752624511719], [1017.6467895507812, 305.8353271484375, 1048.638427734375, 378.24951171875], [0.0, 430.8117370605469, 33.72998809814453, 516.1450805664062]]\n",
            "Tap Coord: (1050, 582)\n",
            "Min distance:  7.106335201775948\n",
            "Cropping frame\n",
            "Red percentage:  38.51609383524277\n",
            "In load_person_dect_model\n",
            "\n",
            "\n",
            "WARNING ⚠️ inference results will accumulate in RAM unless `stream=True` is passed, causing potential out-of-memory\n",
            "errors for large sources or long-running streams and videos. See https://docs.ultralytics.com/modes/predict/ for help.\n",
            "\n",
            "Example:\n",
            "    results = model(source=..., stream=True)  # generator of Results objects\n",
            "    for r in results:\n",
            "        boxes = r.boxes  # Boxes object for bbox outputs\n",
            "        masks = r.masks  # Masks object for segment masks outputs\n",
            "        probs = r.probs  # Class probabilities for classification outputs\n",
            "\n",
            "video 1/1 (frame 1/50) /content/video.mp4: 384x640 11 persons, 1261.9ms\n",
            "video 1/1 (frame 2/50) /content/video.mp4: 384x640 11 persons, 927.0ms\n",
            "video 1/1 (frame 3/50) /content/video.mp4: 384x640 11 persons, 918.0ms\n",
            "video 1/1 (frame 4/50) /content/video.mp4: 384x640 12 persons, 906.6ms\n",
            "video 1/1 (frame 5/50) /content/video.mp4: 384x640 14 persons, 928.6ms\n",
            "video 1/1 (frame 6/50) /content/video.mp4: 384x640 15 persons, 915.3ms\n",
            "video 1/1 (frame 7/50) /content/video.mp4: 384x640 15 persons, 904.7ms\n",
            "video 1/1 (frame 8/50) /content/video.mp4: 384x640 15 persons, 949.0ms\n",
            "video 1/1 (frame 9/50) /content/video.mp4: 384x640 15 persons, 961.2ms\n",
            "video 1/1 (frame 10/50) /content/video.mp4: 384x640 15 persons, 950.1ms\n",
            "video 1/1 (frame 11/50) /content/video.mp4: 384x640 15 persons, 1044.0ms\n",
            "video 1/1 (frame 12/50) /content/video.mp4: 384x640 15 persons, 1495.5ms\n",
            "video 1/1 (frame 13/50) /content/video.mp4: 384x640 15 persons, 1499.4ms\n",
            "video 1/1 (frame 14/50) /content/video.mp4: 384x640 15 persons, 1518.3ms\n",
            "video 1/1 (frame 15/50) /content/video.mp4: 384x640 13 persons, 971.1ms\n",
            "video 1/1 (frame 16/50) /content/video.mp4: 384x640 14 persons, 937.8ms\n",
            "video 1/1 (frame 17/50) /content/video.mp4: 384x640 14 persons, 936.9ms\n",
            "video 1/1 (frame 18/50) /content/video.mp4: 384x640 14 persons, 956.1ms\n",
            "video 1/1 (frame 19/50) /content/video.mp4: 384x640 14 persons, 951.7ms\n",
            "video 1/1 (frame 20/50) /content/video.mp4: 384x640 14 persons, 937.3ms\n",
            "video 1/1 (frame 21/50) /content/video.mp4: 384x640 14 persons, 939.2ms\n",
            "video 1/1 (frame 22/50) /content/video.mp4: 384x640 14 persons, 961.3ms\n",
            "video 1/1 (frame 23/50) /content/video.mp4: 384x640 14 persons, 948.1ms\n",
            "video 1/1 (frame 24/50) /content/video.mp4: 384x640 14 persons, 982.1ms\n",
            "video 1/1 (frame 25/50) /content/video.mp4: 384x640 14 persons, 1504.3ms\n",
            "video 1/1 (frame 26/50) /content/video.mp4: 384x640 14 persons, 1516.0ms\n",
            "video 1/1 (frame 27/50) /content/video.mp4: 384x640 14 persons, 1557.4ms\n",
            "video 1/1 (frame 28/50) /content/video.mp4: 384x640 14 persons, 947.9ms\n",
            "video 1/1 (frame 29/50) /content/video.mp4: 384x640 14 persons, 936.1ms\n",
            "video 1/1 (frame 30/50) /content/video.mp4: 384x640 15 persons, 941.5ms\n",
            "video 1/1 (frame 31/50) /content/video.mp4: 384x640 15 persons, 942.9ms\n",
            "video 1/1 (frame 32/50) /content/video.mp4: 384x640 15 persons, 944.3ms\n",
            "video 1/1 (frame 33/50) /content/video.mp4: 384x640 15 persons, 949.9ms\n",
            "video 1/1 (frame 34/50) /content/video.mp4: 384x640 15 persons, 966.7ms\n",
            "video 1/1 (frame 35/50) /content/video.mp4: 384x640 14 persons, 960.9ms\n",
            "video 1/1 (frame 36/50) /content/video.mp4: 384x640 15 persons, 973.9ms\n",
            "video 1/1 (frame 37/50) /content/video.mp4: 384x640 15 persons, 987.6ms\n",
            "video 1/1 (frame 38/50) /content/video.mp4: 384x640 15 persons, 1515.1ms\n",
            "video 1/1 (frame 39/50) /content/video.mp4: 384x640 15 persons, 1502.9ms\n",
            "video 1/1 (frame 40/50) /content/video.mp4: 384x640 15 persons, 1533.9ms\n",
            "video 1/1 (frame 41/50) /content/video.mp4: 384x640 15 persons, 1015.5ms\n",
            "video 1/1 (frame 42/50) /content/video.mp4: 384x640 15 persons, 961.2ms\n",
            "video 1/1 (frame 43/50) /content/video.mp4: 384x640 15 persons, 953.8ms\n",
            "video 1/1 (frame 44/50) /content/video.mp4: 384x640 15 persons, 952.0ms\n",
            "video 1/1 (frame 45/50) /content/video.mp4: 384x640 15 persons, 955.4ms\n",
            "video 1/1 (frame 46/50) /content/video.mp4: 384x640 15 persons, 951.8ms\n",
            "video 1/1 (frame 47/50) /content/video.mp4: 384x640 15 persons, 950.2ms\n",
            "video 1/1 (frame 48/50) /content/video.mp4: 384x640 15 persons, 976.9ms\n",
            "video 1/1 (frame 49/50) /content/video.mp4: 384x640 15 persons, 941.7ms\n",
            "video 1/1 (frame 50/50) /content/video.mp4: 384x640 15 persons, 945.1ms\n",
            "Speed: 4.6ms preprocess, 1059.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/track8\u001b[0m\n",
            "In get_tapped_box\n",
            "Tracking ID:  1.0\n",
            "Tracking ID:  4.0\n",
            "Tracking ID:  10.0\n",
            "Tracking ID:  15.0\n",
            "In load_jersey_dect_model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2024-5-1 Python-3.10.12 torch-2.2.1+cu121 CPU\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 213 layers, 7279825 parameters, 0 gradients, 16.6 GFLOPs\n",
            "Adding AutoShape... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In clear_output_folder\n",
            "In pre_process_images\n",
            "In get_jersey_number\n",
            "In predict_number\n",
            "In predict_number\n",
            "In predict_number\n",
            "In predict_number\n",
            "In predict_number\n",
            "In predict_number\n",
            "In predict_number\n",
            "In predict_number\n",
            "In predict_number\n",
            "In predict_number\n",
            "In predict_number\n",
            "In predict_number\n",
            "In predict_number\n",
            "In predict_number\n",
            "In predict_number\n",
            "In predict_number\n",
            "In predict_number\n",
            "In predict_number\n",
            "In predict_number\n",
            "In predict_number\n",
            "In predict_number\n",
            "In predict_number\n",
            "In predict_number\n",
            "In predict_number\n",
            "In predict_number\n",
            "In predict_number\n",
            "In predict_number\n",
            "In predict_number\n",
            "In predict_number\n",
            "In predict_number\n",
            "In predict_number\n",
            "In predict_number\n",
            "In predict_number\n",
            "In predict_number\n",
            "In predict_number\n",
            "In predict_number\n",
            "In predict_number\n",
            "In predict_number\n",
            "In predict_number\n",
            "In predict_number\n",
            "In predict_number\n",
            "In predict_number\n",
            "In predict_number\n",
            "In predict_number\n",
            "{14: 2}\n",
            "INFO:     182.180.38.253:0 - \"POST /predict/ HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:     Shutting down\n",
            "INFO:     Waiting for application shutdown.\n",
            "INFO:     Application shutdown complete.\n",
            "INFO:     Finished server process [144]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-c24ee53acfd2>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Public URL:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mngrok_tunnel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpublic_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mnest_asyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0muvicorn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/uvicorn/main.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(app, host, port, uds, fd, loop, http, ws, ws_max_size, ws_max_queue, ws_ping_interval, ws_ping_timeout, ws_per_message_deflate, lifespan, interface, reload, reload_dirs, reload_includes, reload_excludes, reload_delay, workers, env_file, log_config, log_level, access_log, proxy_headers, server_header, date_header, forwarded_allow_ips, root_path, limit_concurrency, backlog, limit_max_requests, timeout_keep_alive, timeout_graceful_shutdown, ssl_keyfile, ssl_certfile, ssl_keyfile_password, ssl_version, ssl_cert_reqs, ssl_ca_certs, ssl_ciphers, headers, use_colors, app_dir, factory, h11_max_incomplete_event_size)\u001b[0m\n\u001b[1;32m    573\u001b[0m         \u001b[0mMultiprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mserver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msockets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m         \u001b[0mserver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muds\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pragma: py-win32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/uvicorn/server.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, sockets)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msockets\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_event_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msockets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msockets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mserve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msockets\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nest_asyncio.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(main, debug)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mtask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_future\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_until_complete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nest_asyncio.py\u001b[0m in \u001b[0;36mrun_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_destroy_pending\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stopping\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nest_asyncio.py\u001b[0m in \u001b[0;36m_run_once\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m                     \u001b[0mhandle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m                 \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m                     \u001b[0;31m# restore the current task\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/asyncio/events.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSystemExit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/asyncio/tasks.py\u001b[0m in \u001b[0;36m__wakeup\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0;31m# instead of `__next__()`, which is slower for futures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0;31m# that return non-generator iterators from their `__iter__`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# Needed to break cycles when an exception occurs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/asyncio/tasks.py\u001b[0m in \u001b[0;36m__step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    230\u001b[0m                 \u001b[0;31m# We use the `send` method directly, because coroutines\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m                 \u001b[0;31m# don't have `__iter__` and `__next__` methods.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/uvicorn/server.py\u001b[0m in \u001b[0;36mserve\u001b[0;34m(self, sockets)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mserve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msockets\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapture_signals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m             \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_serve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msockets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/uvicorn/server.py\u001b[0m in \u001b[0;36mcapture_signals\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0;31m# done LIFO, see https://stackoverflow.com/questions/48434964\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcaptured_signal\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_captured_signals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m             \u001b[0msignal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_signal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcaptured_signal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhandle_exit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFrameType\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "print(\"Enter your authtoken, which can be copied from https://dashboard.ngrok.com/get-started/your-authtoken\")\n",
        "conf.get_default().auth_token = \"2f12n34CoKYGCV5XWBXCgwZ6Frx_4vpCZthbo8DF4eHgkpVoA\"\n",
        "\n",
        "ngrok_tunnel = ngrok.connect(8000)\n",
        "print('Public URL:', ngrok_tunnel.public_url)\n",
        "nest_asyncio.apply()\n",
        "uvicorn.run(app, port=8000)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}